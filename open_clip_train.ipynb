{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68397693",
   "metadata": {},
   "source": [
    "# Training Open Clip from ML Foundations\n",
    "\n",
    "https://github.com/mlfoundations/open_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f2f40",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668bf974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: open_clip_torch[training] in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (2.16.0)\n",
      "Requirement already satisfied: torch in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: tqdm in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (4.65.0)\n",
      "Requirement already satisfied: sentencepiece in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (0.1.97)\n",
      "Requirement already satisfied: protobuf<4 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (0.13.3)\n",
      "Requirement already satisfied: timm in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (0.6.13)\n",
      "Requirement already satisfied: ftfy in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (6.1.1)\n",
      "Requirement already satisfied: regex in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (2022.10.31)\n",
      "Requirement already satisfied: pandas in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (1.5.3)\n",
      "Requirement already satisfied: fsspec in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (2023.3.0)\n",
      "Requirement already satisfied: braceexpand in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (0.1.7)\n",
      "Requirement already satisfied: webdataset>=0.2.5 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (0.2.48)\n",
      "Requirement already satisfied: transformers in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from open_clip_torch[training]) (4.27.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: typing-extensions in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: jinja2 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: filelock in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: networkx in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: setuptools in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: lit in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.0)\n",
      "Requirement already satisfied: cmake in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.0)\n",
      "Requirement already satisfied: requests in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: pyyaml in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from webdataset>=0.2.5->open_clip_torch[training]) (6.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from ftfy->open_clip_torch[training]) (0.2.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch[training]) (22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from pandas->open_clip_torch[training]) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from pandas->open_clip_torch[training]) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from transformers->open_clip_torch[training]) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->open_clip_torch[training]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'open_clip_torch[training]' torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27022e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f98c4",
   "metadata": {},
   "source": [
    "### Check CLI installed as a python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5163b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--train-data TRAIN_DATA]\r\n",
      "               [--train-data-upsampling-factors TRAIN_DATA_UPSAMPLING_FACTORS]\r\n",
      "               [--val-data VAL_DATA] [--train-num-samples TRAIN_NUM_SAMPLES]\r\n",
      "               [--val-num-samples VAL_NUM_SAMPLES]\r\n",
      "               [--dataset-type {webdataset,csv,synthetic,auto}]\r\n",
      "               [--dataset-resampled] [--csv-separator CSV_SEPARATOR]\r\n",
      "               [--csv-img-key CSV_IMG_KEY] [--csv-caption-key CSV_CAPTION_KEY]\r\n",
      "               [--imagenet-val IMAGENET_VAL] [--imagenet-v2 IMAGENET_V2]\r\n",
      "               [--logs LOGS] [--log-local] [--name NAME] [--workers WORKERS]\r\n",
      "               [--batch-size BATCH_SIZE] [--epochs EPOCHS]\r\n",
      "               [--epochs-cooldown EPOCHS_COOLDOWN] [--lr LR] [--beta1 BETA1]\r\n",
      "               [--beta2 BETA2] [--eps EPS] [--wd WD] [--warmup WARMUP]\r\n",
      "               [--use-bn-sync] [--skip-scheduler]\r\n",
      "               [--lr-scheduler LR_SCHEDULER]\r\n",
      "               [--lr-cooldown-end LR_COOLDOWN_END]\r\n",
      "               [--lr-cooldown-power LR_COOLDOWN_POWER]\r\n",
      "               [--save-frequency SAVE_FREQUENCY] [--save-most-recent]\r\n",
      "               [--zeroshot-frequency ZEROSHOT_FREQUENCY]\r\n",
      "               [--val-frequency VAL_FREQUENCY] [--resume RESUME]\r\n",
      "               [--precision {amp,amp_bf16,amp_bfloat16,bf16,fp16,fp32}]\r\n",
      "               [--model MODEL] [--pretrained PRETRAINED] [--pretrained-image]\r\n",
      "               [--lock-image]\r\n",
      "               [--lock-image-unlocked-groups LOCK_IMAGE_UNLOCKED_GROUPS]\r\n",
      "               [--lock-image-freeze-bn-stats] [--image-mean MEAN [MEAN ...]]\r\n",
      "               [--image-std STD [STD ...]] [--aug-cfg [AUG_CFG ...]]\r\n",
      "               [--grad-checkpointing] [--local-loss] [--gather-with-grad]\r\n",
      "               [--force-image-size FORCE_IMAGE_SIZE [FORCE_IMAGE_SIZE ...]]\r\n",
      "               [--force-quick-gelu]\r\n",
      "               [--force-patch-dropout FORCE_PATCH_DROPOUT]\r\n",
      "               [--force-custom-text] [--torchscript] [--trace]\r\n",
      "               [--accum-freq ACCUM_FREQ] [--dist-url DIST_URL]\r\n",
      "               [--dist-backend DIST_BACKEND] [--report-to REPORT_TO]\r\n",
      "               [--wandb-notes WANDB_NOTES]\r\n",
      "               [--wandb-project-name WANDB_PROJECT_NAME] [--debug]\r\n",
      "               [--copy-codebase] [--horovod] [--ddp-static-graph]\r\n",
      "               [--no-set-device-rank] [--seed SEED]\r\n",
      "               [--grad-clip-norm GRAD_CLIP_NORM] [--lock-text]\r\n",
      "               [--lock-text-unlocked-layers LOCK_TEXT_UNLOCKED_LAYERS]\r\n",
      "               [--lock-text-freeze-layer-norm]\r\n",
      "               [--log-every-n-steps LOG_EVERY_N_STEPS]\r\n",
      "               [--coca-caption-loss-weight COCA_CAPTION_LOSS_WEIGHT]\r\n",
      "               [--coca-contrastive-loss-weight COCA_CONTRASTIVE_LOSS_WEIGHT]\r\n",
      "               [--remote-sync REMOTE_SYNC]\r\n",
      "               [--remote-sync-frequency REMOTE_SYNC_FREQUENCY]\r\n",
      "               [--remote-sync-protocol {s3,fsspec}]\r\n",
      "               [--delete-previous-checkpoint] [--distill-model DISTILL_MODEL]\r\n",
      "               [--distill-pretrained DISTILL_PRETRAINED]\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --train-data TRAIN_DATA\r\n",
      "                        Path to file(s) with training data. When using\r\n",
      "                        webdataset, multiple datasources can be combined using\r\n",
      "                        the `::` separator.\r\n",
      "  --train-data-upsampling-factors TRAIN_DATA_UPSAMPLING_FACTORS\r\n",
      "                        When using multiple data sources with webdataset and\r\n",
      "                        sampling with replacement, this can be used to\r\n",
      "                        upsample specific data sources. Similar to --train-\r\n",
      "                        data, this should be a string with as many numbers as\r\n",
      "                        there are data sources, separated by `::` (e.g.\r\n",
      "                        1::2::0.5) By default, datapoints are sampled\r\n",
      "                        uniformly regardless of the dataset sizes.\r\n",
      "  --val-data VAL_DATA   Path to file(s) with validation data\r\n",
      "  --train-num-samples TRAIN_NUM_SAMPLES\r\n",
      "                        Number of samples in dataset. Required for webdataset\r\n",
      "                        if not available in info file.\r\n",
      "  --val-num-samples VAL_NUM_SAMPLES\r\n",
      "                        Number of samples in dataset. Useful for webdataset if\r\n",
      "                        not available in info file.\r\n",
      "  --dataset-type {webdataset,csv,synthetic,auto}\r\n",
      "                        Which type of dataset to process.\r\n",
      "  --dataset-resampled   Whether to use sampling with replacement for\r\n",
      "                        webdataset shard selection.\r\n",
      "  --csv-separator CSV_SEPARATOR\r\n",
      "                        For csv-like datasets, which separator to use.\r\n",
      "  --csv-img-key CSV_IMG_KEY\r\n",
      "                        For csv-like datasets, the name of the key for the\r\n",
      "                        image paths.\r\n",
      "  --csv-caption-key CSV_CAPTION_KEY\r\n",
      "                        For csv-like datasets, the name of the key for the\r\n",
      "                        captions.\r\n",
      "  --imagenet-val IMAGENET_VAL\r\n",
      "                        Path to imagenet val set for conducting zero shot\r\n",
      "                        evaluation.\r\n",
      "  --imagenet-v2 IMAGENET_V2\r\n",
      "                        Path to imagenet v2 for conducting zero shot\r\n",
      "                        evaluation.\r\n",
      "  --logs LOGS           Where to store tensorboard logs. Use None to avoid\r\n",
      "                        storing logs.\r\n",
      "  --log-local           log files on local master, otherwise global master\r\n",
      "                        only.\r\n",
      "  --name NAME           Optional identifier for the experiment when storing\r\n",
      "                        logs. Otherwise use current time.\r\n",
      "  --workers WORKERS     Number of dataloader workers per GPU.\r\n",
      "  --batch-size BATCH_SIZE\r\n",
      "                        Batch size per GPU.\r\n",
      "  --epochs EPOCHS       Number of epochs to train for.\r\n",
      "  --epochs-cooldown EPOCHS_COOLDOWN\r\n",
      "                        When scheduler w/ cooldown used, perform cooldown from\r\n",
      "                        total_epochs - cooldown_epochs onwards.\r\n",
      "  --lr LR               Learning rate.\r\n",
      "  --beta1 BETA1         Adam beta 1.\r\n",
      "  --beta2 BETA2         Adam beta 2.\r\n",
      "  --eps EPS             Adam epsilon.\r\n",
      "  --wd WD               Weight decay.\r\n",
      "  --warmup WARMUP       Number of steps to warmup for.\r\n",
      "  --use-bn-sync         Whether to use batch norm sync.\r\n",
      "  --skip-scheduler      Use this flag to skip the learning rate decay.\r\n",
      "  --lr-scheduler LR_SCHEDULER\r\n",
      "                        LR scheduler. One of: 'cosine', 'const' (constant),\r\n",
      "                        'const-cooldown' (constant w/ cooldown). Default:\r\n",
      "                        cosine\r\n",
      "  --lr-cooldown-end LR_COOLDOWN_END\r\n",
      "                        End learning rate for cooldown schedule. Default: 0\r\n",
      "  --lr-cooldown-power LR_COOLDOWN_POWER\r\n",
      "                        Power for polynomial cooldown schedule. Default: 1.0\r\n",
      "                        (linear decay)\r\n",
      "  --save-frequency SAVE_FREQUENCY\r\n",
      "                        How often to save checkpoints.\r\n",
      "  --save-most-recent    Always save the most recent model trained to\r\n",
      "                        epoch_latest.pt.\r\n",
      "  --zeroshot-frequency ZEROSHOT_FREQUENCY\r\n",
      "                        How often to run zero shot.\r\n",
      "  --val-frequency VAL_FREQUENCY\r\n",
      "                        How often to run evaluation with val data.\r\n",
      "  --resume RESUME       path to latest checkpoint (default: none)\r\n",
      "  --precision {amp,amp_bf16,amp_bfloat16,bf16,fp16,fp32}\r\n",
      "                        Floating point precision.\r\n",
      "  --model MODEL         Name of the vision backbone to use.\r\n",
      "  --pretrained PRETRAINED\r\n",
      "                        Use a pretrained CLIP model weights with the specified\r\n",
      "                        tag or file path.\r\n",
      "  --pretrained-image    Load imagenet pretrained weights for image tower\r\n",
      "                        backbone if available.\r\n",
      "  --lock-image          Lock full image tower by disabling gradients.\r\n",
      "  --lock-image-unlocked-groups LOCK_IMAGE_UNLOCKED_GROUPS\r\n",
      "                        Leave last n image tower layer groups unlocked.\r\n",
      "  --lock-image-freeze-bn-stats\r\n",
      "                        Freeze BatchNorm running stats in image tower for any\r\n",
      "                        locked layers.\r\n",
      "  --image-mean MEAN [MEAN ...]\r\n",
      "                        Override default image mean value of dataset\r\n",
      "  --image-std STD [STD ...]\r\n",
      "                        Override default image std deviation of of dataset\r\n",
      "  --aug-cfg [AUG_CFG ...]\r\n",
      "  --grad-checkpointing  Enable gradient checkpointing.\r\n",
      "  --local-loss          calculate loss w/ local features @ global (instead of\r\n",
      "                        realizing full global @ global matrix)\r\n",
      "  --gather-with-grad    enable full distributed gradient for feature gather\r\n",
      "  --force-image-size FORCE_IMAGE_SIZE [FORCE_IMAGE_SIZE ...]\r\n",
      "                        Override default image size\r\n",
      "  --force-quick-gelu    Force use of QuickGELU activation for non-OpenAI\r\n",
      "                        transformer models.\r\n",
      "  --force-patch-dropout FORCE_PATCH_DROPOUT\r\n",
      "                        Override the patch dropout during training, for fine\r\n",
      "                        tuning with no dropout near the end as in the paper\r\n",
      "  --force-custom-text   Force use of CustomTextCLIP model (separate text-\r\n",
      "                        tower).\r\n",
      "  --torchscript         torch.jit.script the model, also uses jit version of\r\n",
      "                        OpenAI models if pretrained=='openai'\r\n",
      "  --trace               torch.jit.trace the model for inference / eval only\r\n",
      "  --accum-freq ACCUM_FREQ\r\n",
      "                        Update the model every --acum-freq steps.\r\n",
      "  --dist-url DIST_URL   url used to set up distributed training\r\n",
      "  --dist-backend DIST_BACKEND\r\n",
      "                        distributed backend\r\n",
      "  --report-to REPORT_TO\r\n",
      "                        Options are ['wandb', 'tensorboard',\r\n",
      "                        'wandb,tensorboard']\r\n",
      "  --wandb-notes WANDB_NOTES\r\n",
      "                        Notes if logging with wandb\r\n",
      "  --wandb-project-name WANDB_PROJECT_NAME\r\n",
      "                        Name of the project if logging with wandb.\r\n",
      "  --debug               If true, more information is logged.\r\n",
      "  --copy-codebase       If true, we copy the entire base on the log directory,\r\n",
      "                        and execute from there.\r\n",
      "  --horovod             Use horovod for distributed training.\r\n",
      "  --ddp-static-graph    Enable static graph optimization for DDP in PyTorch >=\r\n",
      "                        1.11.\r\n",
      "  --no-set-device-rank  Don't set device index from local rank (when\r\n",
      "                        CUDA_VISIBLE_DEVICES restricted to one per proc).\r\n",
      "  --seed SEED           Default random seed.\r\n",
      "  --grad-clip-norm GRAD_CLIP_NORM\r\n",
      "                        Gradient clip.\r\n",
      "  --lock-text           Lock full text tower by disabling gradients.\r\n",
      "  --lock-text-unlocked-layers LOCK_TEXT_UNLOCKED_LAYERS\r\n",
      "                        Leave last n image tower layer groups unlocked.\r\n",
      "  --lock-text-freeze-layer-norm\r\n",
      "                        Freeze BatchNorm running stats in image tower for any\r\n",
      "                        locked layers.\r\n",
      "  --log-every-n-steps LOG_EVERY_N_STEPS\r\n",
      "                        Log every n steps to tensorboard/console/wandb.\r\n",
      "  --coca-caption-loss-weight COCA_CAPTION_LOSS_WEIGHT\r\n",
      "                        Weight assigned to caption loss in CoCa.\r\n",
      "  --coca-contrastive-loss-weight COCA_CONTRASTIVE_LOSS_WEIGHT\r\n",
      "                        Weight assigned to contrastive loss when training\r\n",
      "                        CoCa.\r\n",
      "  --remote-sync REMOTE_SYNC\r\n",
      "                        Optinoally sync with a remote path specified by this\r\n",
      "                        arg\r\n",
      "  --remote-sync-frequency REMOTE_SYNC_FREQUENCY\r\n",
      "                        How frequently to sync to a remote directly if\r\n",
      "                        --remote-sync is not None.\r\n",
      "  --remote-sync-protocol {s3,fsspec}\r\n",
      "                        How to do the remote sync backup if --remote-sync is\r\n",
      "                        not None.\r\n",
      "  --delete-previous-checkpoint\r\n",
      "                        If true, delete previous checkpoint after storing a\r\n",
      "                        new one.\r\n",
      "  --distill-model DISTILL_MODEL\r\n",
      "                        Which model arch to distill from, if any.\r\n",
      "  --distill-pretrained DISTILL_PRETRAINED\r\n",
      "                        Which pre-trained weights to distill from, if any.\r\n"
     ]
    }
   ],
   "source": [
    "!python -m training.main --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7ae228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-24,20:46:45 | INFO | Running with a single process. Device cuda:0.\n",
      "2023-03-24,20:46:45 | INFO | Loaded RN50 model config.\n",
      "2023-03-24,20:46:48 | INFO | Model:\n",
      "2023-03-24,20:46:48 | INFO | CLIP(\n",
      "  (visual): ModifiedResNet(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act3): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (attnpool): AttentionPool2d(\n",
      "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (token_embedding): Embedding(49408, 512)\n",
      "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "2023-03-24,20:46:48 | INFO | Params:\n",
      "2023-03-24,20:46:48 | INFO |   accum_freq: 1\n",
      "2023-03-24,20:46:48 | INFO |   aug_cfg: {}\n",
      "2023-03-24,20:46:48 | INFO |   batch_size: 64\n",
      "2023-03-24,20:46:48 | INFO |   beta1: 0.9\n",
      "2023-03-24,20:46:48 | INFO |   beta2: 0.999\n",
      "2023-03-24,20:46:48 | INFO |   checkpoint_path: ./logs/2023_03_24-20_46_45-model_RN50-lr_0.0005-b_64-j_1-p_amp/checkpoints\n",
      "2023-03-24,20:46:48 | INFO |   coca_caption_loss_weight: 2.0\n",
      "2023-03-24,20:46:48 | INFO |   coca_contrastive_loss_weight: 1.0\n",
      "2023-03-24,20:46:48 | INFO |   copy_codebase: False\n",
      "2023-03-24,20:46:48 | INFO |   csv_caption_key: caption\n",
      "2023-03-24,20:46:48 | INFO |   csv_img_key: url\n",
      "2023-03-24,20:46:48 | INFO |   csv_separator: \t\n",
      "2023-03-24,20:46:48 | INFO |   dataset_resampled: False\n",
      "2023-03-24,20:46:48 | INFO |   dataset_type: auto\n",
      "2023-03-24,20:46:48 | INFO |   ddp_static_graph: False\n",
      "2023-03-24,20:46:48 | INFO |   debug: False\n",
      "2023-03-24,20:46:48 | INFO |   delete_previous_checkpoint: False\n",
      "2023-03-24,20:46:48 | INFO |   device: cuda:0\n",
      "2023-03-24,20:46:48 | INFO |   dist_backend: nccl\n",
      "2023-03-24,20:46:48 | INFO |   dist_url: env://\n",
      "2023-03-24,20:46:48 | INFO |   distill: False\n",
      "2023-03-24,20:46:48 | INFO |   distill_model: None\n",
      "2023-03-24,20:46:48 | INFO |   distill_pretrained: None\n",
      "2023-03-24,20:46:48 | INFO |   distributed: False\n",
      "2023-03-24,20:46:48 | INFO |   epochs: 32\n",
      "2023-03-24,20:46:48 | INFO |   epochs_cooldown: None\n",
      "2023-03-24,20:46:48 | INFO |   eps: 1e-08\n",
      "2023-03-24,20:46:48 | INFO |   force_custom_text: False\n",
      "2023-03-24,20:46:48 | INFO |   force_image_size: None\n",
      "2023-03-24,20:46:48 | INFO |   force_patch_dropout: None\n",
      "2023-03-24,20:46:48 | INFO |   force_quick_gelu: False\n",
      "2023-03-24,20:46:48 | INFO |   gather_with_grad: False\n",
      "2023-03-24,20:46:48 | INFO |   grad_checkpointing: False\n",
      "2023-03-24,20:46:48 | INFO |   grad_clip_norm: None\n",
      "2023-03-24,20:46:48 | INFO |   horovod: False\n",
      "2023-03-24,20:46:48 | INFO |   image_mean: None\n",
      "2023-03-24,20:46:48 | INFO |   image_std: None\n",
      "2023-03-24,20:46:48 | INFO |   imagenet_v2: None\n",
      "2023-03-24,20:46:48 | INFO |   imagenet_val: None\n",
      "2023-03-24,20:46:48 | INFO |   local_loss: False\n",
      "2023-03-24,20:46:48 | INFO |   local_rank: 0\n",
      "2023-03-24,20:46:48 | INFO |   lock_image: False\n",
      "2023-03-24,20:46:48 | INFO |   lock_image_freeze_bn_stats: False\n",
      "2023-03-24,20:46:48 | INFO |   lock_image_unlocked_groups: 0\n",
      "2023-03-24,20:46:48 | INFO |   lock_text: False\n",
      "2023-03-24,20:46:48 | INFO |   lock_text_freeze_layer_norm: False\n",
      "2023-03-24,20:46:48 | INFO |   lock_text_unlocked_layers: 0\n",
      "2023-03-24,20:46:48 | INFO |   log_every_n_steps: 100\n",
      "2023-03-24,20:46:48 | INFO |   log_level: 20\n",
      "2023-03-24,20:46:48 | INFO |   log_local: False\n",
      "2023-03-24,20:46:48 | INFO |   log_path: ./logs/2023_03_24-20_46_45-model_RN50-lr_0.0005-b_64-j_1-p_amp/out.log\n",
      "2023-03-24,20:46:48 | INFO |   logs: ./logs/\n",
      "2023-03-24,20:46:48 | INFO |   lr: 0.0005\n",
      "2023-03-24,20:46:48 | INFO |   lr_cooldown_end: 0.0\n",
      "2023-03-24,20:46:48 | INFO |   lr_cooldown_power: 1.0\n",
      "2023-03-24,20:46:48 | INFO |   lr_scheduler: cosine\n",
      "2023-03-24,20:46:48 | INFO |   model: RN50\n",
      "2023-03-24,20:46:48 | INFO |   name: 2023_03_24-20_46_45-model_RN50-lr_0.0005-b_64-j_1-p_amp\n",
      "2023-03-24,20:46:48 | INFO |   no_set_device_rank: False\n",
      "2023-03-24,20:46:48 | INFO |   precision: amp\n",
      "2023-03-24,20:46:48 | INFO |   pretrained: \n",
      "2023-03-24,20:46:48 | INFO |   pretrained_image: False\n",
      "2023-03-24,20:46:48 | INFO |   rank: 0\n",
      "2023-03-24,20:46:48 | INFO |   remote_sync: None\n",
      "2023-03-24,20:46:48 | INFO |   remote_sync_frequency: 300\n",
      "2023-03-24,20:46:48 | INFO |   remote_sync_protocol: s3\n",
      "2023-03-24,20:46:48 | INFO |   report_to: tensorboard\n",
      "2023-03-24,20:46:48 | INFO |   resume: None\n",
      "2023-03-24,20:46:48 | INFO |   save_frequency: 1\n",
      "2023-03-24,20:46:48 | INFO |   save_most_recent: False\n",
      "2023-03-24,20:46:48 | INFO |   seed: 0\n",
      "2023-03-24,20:46:48 | INFO |   skip_scheduler: False\n",
      "2023-03-24,20:46:48 | INFO |   tensorboard: True\n",
      "2023-03-24,20:46:48 | INFO |   tensorboard_path: ./logs/2023_03_24-20_46_45-model_RN50-lr_0.0005-b_64-j_1-p_amp/tensorboard\n",
      "2023-03-24,20:46:48 | INFO |   torchscript: False\n",
      "2023-03-24,20:46:48 | INFO |   trace: False\n",
      "2023-03-24,20:46:48 | INFO |   train_data: /home/msouza/clip/jupyter-notebooks/open_clip/dataset-disasters/file_and_sentiment_train.csv\n",
      "2023-03-24,20:46:48 | INFO |   train_data_upsampling_factors: None\n",
      "2023-03-24,20:46:48 | INFO |   train_num_samples: None\n",
      "2023-03-24,20:46:48 | INFO |   use_bn_sync: False\n",
      "2023-03-24,20:46:48 | INFO |   val_data: /home/msouza/clip/jupyter-notebooks/open_clip/dataset-disasters/file_and_sentiment_val.csv\n",
      "2023-03-24,20:46:48 | INFO |   val_frequency: 1\n",
      "2023-03-24,20:46:48 | INFO |   val_num_samples: None\n",
      "2023-03-24,20:46:48 | INFO |   wandb: False\n",
      "2023-03-24,20:46:48 | INFO |   wandb_notes: \n",
      "2023-03-24,20:46:48 | INFO |   wandb_project_name: open-clip\n",
      "2023-03-24,20:46:48 | INFO |   warmup: 10000\n",
      "2023-03-24,20:46:48 | INFO |   wd: 0.2\n",
      "2023-03-24,20:46:48 | INFO |   workers: 1\n",
      "2023-03-24,20:46:48 | INFO |   world_size: 1\n",
      "2023-03-24,20:46:48 | INFO |   zeroshot_frequency: 1\n",
      "2023-03-24,20:46:48 | INFO | Start epoch 0\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/runpy.py\", line 86, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/training/main.py\", line 470, in <module>\r\n",
      "    main(sys.argv[1:])\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/training/main.py\", line 398, in main\r\n",
      "    train_one_epoch(model, data, loss, epoch, optimizer, scaler, scheduler, dist_model, args, tb_writer=writer)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/training/train.py\", line 100, in train_one_epoch\r\n",
      "    model_out = model(images, texts)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/open_clip/model.py\", line 231, in forward\r\n",
      "    image_features = self.encode_image(image, normalize=True)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/open_clip/model.py\", line 213, in encode_image\r\n",
      "    features = self.visual(image)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/open_clip/modified_resnet.py\", line 178, in forward\r\n",
      "    x = self.layer4(x)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\r\n",
      "    input = module(input)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/open_clip/modified_resnet.py\", line 46, in forward\r\n",
      "    out = self.act2(self.bn2(self.conv2(out)))\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\r\n",
      "    return self._conv_forward(input, self.weight, self.bias)\r\n",
      "  File \"/home/msouza/anaconda3/envs/clip/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\r\n",
      "    return F.conv2d(input, weight, bias, self.stride,\r\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 3.31 GiB already allocated; 26.75 MiB free; 3.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n"
     ]
    }
   ],
   "source": [
    "!python -m training.main \\\n",
    "    --save-frequency 1 \\\n",
    "    --zeroshot-frequency 1 \\\n",
    "    --report-to tensorboard \\\n",
    "    --train-data=\"/home/msouza/clip/jupyter-notebooks/open_clip/dataset-disasters/file_and_sentiment_train.csv\" \\\n",
    "    --val-data=\"/home/msouza/clip/jupyter-notebooks/open_clip/dataset-disasters/file_and_sentiment_val.csv\" \\\n",
    "    --csv-img-key url \\\n",
    "    --csv-caption-key caption \\\n",
    "    #--imagenet-val=/path/to/imagenet/root/val/ \\\n",
    "    #--warmup 10000 \\\n",
    "    --batch-size=128 \\\n",
    "    --lr=1e-3 \\\n",
    "    --wd=0.1 \\\n",
    "    --epochs=1 \\\n",
    "    --workers=1 \\\n",
    "    #--model RN50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_clip",
   "language": "python",
   "name": "open_clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
